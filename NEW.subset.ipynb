{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd, numpy as np, matplotlib, matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "from skimage import io, color\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([256,256]),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "validation_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([256,256]),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "class BoneAgeDataset_TL(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.data_frame.iloc[idx, 0])\n",
    "        \n",
    "        image = io.imread(img_name)\n",
    "        if len(image.shape) > 2 and image.shape[2] == 4:\n",
    "            image = image[:,:,0]\n",
    "            \n",
    "        # replicate the image into 3 RGB channels\n",
    "        image=np.repeat(image[None,...],3,axis=0)\n",
    "            \n",
    "        image_age = self.data_frame.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        sample = {'x': image, 'y': image_age}\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "BoneAge_TrainData = BoneAgeDataset_TL(csv_file='data/random_train_boneage.csv',\n",
    "                                    root_dir='/beegfs/ga4493/projects/team_G/boneage-training-dataset_final', transform=train_transform)\n",
    "train_loader = DataLoader(BoneAge_TrainData, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "BoneAge_ValidationData = BoneAgeDataset_TL(csv_file='data/random_validation_boneage.csv',\n",
    "                                    root_dir='/beegfs/ga4493/projects/team_G/boneage-training-dataset_final', transform=validation_transform)\n",
    "validation_loader = DataLoader(BoneAge_ValidationData, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "dataset_sizes = {'train': len(BoneAge_TrainData), 'val': len(BoneAge_ValidationData)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=40, trainVal=['train','val'],verbose=True):\n",
    "    acc_dict = {'train':[],'val':[]}\n",
    "    loss_dict = {'train':[],'val':[]}\n",
    "    best_loss = 100\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in trainVal:\n",
    "            running_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            if phase == 'train':\n",
    "                imageLoader = train_loader\n",
    "                model.train(True)\n",
    "            else:\n",
    "                imageLoader = validation_loader\n",
    "                model.train(False)\n",
    "                \n",
    "            for data in imageLoader:\n",
    "                image = data['x']\n",
    "                label = data['y']\n",
    "                if use_gpu:\n",
    "                    image = image.type(torch.FloatTensor).cuda()\n",
    "                    label = label.type(torch.FloatTensor).cuda()\n",
    "                else:\n",
    "                    image, label = inputs.type(torch.FloatTensor), label.type(torch.FloatTensor)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(image)\n",
    "                loss = criterion(output, label)\n",
    "                num_imgs = image.size()[0]\n",
    "                running_loss += loss.item()*num_imgs\n",
    "                running_total += num_imgs\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            epoch_loss = float(running_loss)/float(running_total)\n",
    "            #if verbose or (epoch%10 == 0):\n",
    "            print('Phase:{}, epoch loss: {:.4f} '.format(phase, epoch_loss))\n",
    "            loss_dict[phase].append(epoch_loss)\n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = model.state_dict()\n",
    "        if (epoch%10 == 0):\n",
    "            time_elapsed = time.time() - since\n",
    "            print('10 epoch costs {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))    \n",
    "    model.load_state_dict(best_model_wts)    \n",
    "    return model, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = torchvision.models.resnet34(pretrained=True)\n",
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = torch.nn.Linear(num_ftrs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model_resnet.cuda()\n",
    "     #This will optimize only the final layer since other layers the gradient calculation is removed and only parameters from the fc layer is given to the optimizer\n",
    "    optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n",
      "Phase:train, epoch loss: 92.7554 \n",
      "Phase:val, epoch loss: 61.4958 \n",
      "10 epoch costs 3m 24s\n",
      "Epoch 1/39\n",
      "----------\n",
      "Phase:train, epoch loss: 45.3378 \n",
      "Phase:val, epoch loss: 36.8164 \n",
      "Epoch 2/39\n",
      "----------\n",
      "Phase:train, epoch loss: 35.9019 \n",
      "Phase:val, epoch loss: 34.6720 \n",
      "Epoch 3/39\n",
      "----------\n",
      "Phase:train, epoch loss: 35.4179 \n",
      "Phase:val, epoch loss: 35.2528 \n",
      "Epoch 4/39\n",
      "----------\n",
      "Phase:train, epoch loss: 35.3335 \n",
      "Phase:val, epoch loss: 34.0619 \n",
      "Epoch 5/39\n",
      "----------\n",
      "Phase:train, epoch loss: 35.2779 \n",
      "Phase:val, epoch loss: 34.0030 \n",
      "Epoch 6/39\n",
      "----------\n",
      "Phase:train, epoch loss: 35.2723 \n",
      "Phase:val, epoch loss: 33.7427 \n",
      "Epoch 7/39\n",
      "----------\n",
      "Phase:train, epoch loss: 35.1210 \n",
      "Phase:val, epoch loss: 33.8017 \n",
      "Epoch 8/39\n",
      "----------\n",
      "Phase:train, epoch loss: 35.0755 \n",
      "Phase:val, epoch loss: 33.8384 \n",
      "Epoch 9/39\n",
      "----------\n",
      "Phase:train, epoch loss: 35.0454 \n",
      "Phase:val, epoch loss: 33.6585 \n",
      "Epoch 10/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.8662 \n",
      "Phase:val, epoch loss: 33.4544 \n",
      "10 epoch costs 45m 42s\n",
      "Epoch 11/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.8023 \n",
      "Phase:val, epoch loss: 33.6889 \n",
      "Epoch 12/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.8336 \n",
      "Phase:val, epoch loss: 33.9814 \n",
      "Epoch 13/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.7476 \n",
      "Phase:val, epoch loss: 33.0159 \n",
      "Epoch 14/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.6949 \n",
      "Phase:val, epoch loss: 32.9682 \n",
      "Epoch 15/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.6785 \n",
      "Phase:val, epoch loss: 33.3168 \n",
      "Epoch 16/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.6488 \n",
      "Phase:val, epoch loss: 32.8582 \n",
      "Epoch 17/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.5644 \n",
      "Phase:val, epoch loss: 33.0302 \n",
      "Epoch 18/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.5558 \n",
      "Phase:val, epoch loss: 33.1249 \n",
      "Epoch 19/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.5255 \n",
      "Phase:val, epoch loss: 33.1634 \n",
      "Epoch 20/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.5426 \n",
      "Phase:val, epoch loss: 33.8633 \n",
      "10 epoch costs 88m 58s\n",
      "Epoch 21/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.4951 \n",
      "Phase:val, epoch loss: 32.9556 \n",
      "Epoch 22/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.4344 \n",
      "Phase:val, epoch loss: 32.9589 \n",
      "Epoch 23/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.3909 \n",
      "Phase:val, epoch loss: 32.7442 \n",
      "Epoch 24/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.4774 \n",
      "Phase:val, epoch loss: 32.6600 \n",
      "Epoch 25/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.4216 \n",
      "Phase:val, epoch loss: 32.8002 \n",
      "Epoch 26/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.4219 \n",
      "Phase:val, epoch loss: 33.2706 \n",
      "Epoch 27/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.4118 \n",
      "Phase:val, epoch loss: 32.3879 \n",
      "Epoch 28/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.3624 \n",
      "Phase:val, epoch loss: 32.7717 \n",
      "Epoch 29/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.4059 \n",
      "Phase:val, epoch loss: 32.9294 \n",
      "Epoch 30/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.3549 \n",
      "Phase:val, epoch loss: 32.4991 \n",
      "10 epoch costs 144m 46s\n",
      "Epoch 31/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.3125 \n",
      "Phase:val, epoch loss: 32.7237 \n",
      "Epoch 32/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.3278 \n",
      "Phase:val, epoch loss: 32.4267 \n",
      "Epoch 33/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.3213 \n",
      "Phase:val, epoch loss: 32.7200 \n",
      "Epoch 34/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.2503 \n",
      "Phase:val, epoch loss: 32.8139 \n",
      "Epoch 35/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.2761 \n",
      "Phase:val, epoch loss: 32.4082 \n",
      "Epoch 36/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.2377 \n",
      "Phase:val, epoch loss: 32.6256 \n",
      "Epoch 37/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.2377 \n",
      "Phase:val, epoch loss: 32.7619 \n",
      "Epoch 38/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.2778 \n",
      "Phase:val, epoch loss: 32.8428 \n",
      "Epoch 39/39\n",
      "----------\n",
      "Phase:train, epoch loss: 34.2755 \n",
      "Phase:val, epoch loss: 32.3681 \n",
      "Training complete in 195m 38s\n",
      "Best val loss: 32.368147\n"
     ]
    }
   ],
   "source": [
    "best_model, loss_dict = train_model(model_resnet, criterion, optimizer,\n",
    "                       num_epochs=40, trainVal=['train','val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
