{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd, numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "from skimage import color\n",
    "from sklearn import metrics\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=25, trainVal=['train','val'],verbose=True):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    loss2plot = np.zeros([2,num_epochs])\n",
    "    acc2plot  = np.zeros([2,num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in trainVal:\n",
    "            if phase == 'train':\n",
    "                imageLoader = train_loader\n",
    "            else:\n",
    "                imageLoader = validation_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_total=0\n",
    "            running_mad = []\n",
    "            loss_list = []\n",
    "\n",
    "            # Iterate over data.\n",
    "            for idx, sample_batched in enumerate(imageLoader):\n",
    "                # get the inputs\n",
    "                inputs = sample_batched['x']\n",
    "                peds_age = sample_batched['y']\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = inputs.type(torch.FloatTensor).cuda()\n",
    "                    peds_age = peds_age.type(torch.FloatTensor).cuda()\n",
    "                else:\n",
    "                    inputs, peds_age = inputs.type(torch.FloatTensor), peds_age.type(torch.FloatTensor)\n",
    "                \n",
    "                peds_age = peds_age.view(-1,1)\n",
    "                # zero the parameter gradients\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                #outputs = outputs.data\n",
    "                loss = criterion(outputs,peds_age)\n",
    "                optimizer.zero_grad()\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                num_imgs = inputs.size(0)\n",
    "                running_loss += loss.item()*num_imgs\n",
    "                running_total += num_imgs\n",
    "                outputs= outputs.data.cpu().numpy()\n",
    "                peds_age = peds_age.data.cpu().numpy()\n",
    "                difference = mean_absolute_error(peds_age, outputs)\n",
    "                running_mad.append(difference)\n",
    "                loss_list.append(running_loss)\n",
    "                \n",
    "                # backward + optimize only if in training phase\n",
    "            epoch_loss = running_loss / running_total\n",
    "            epoch_acc = np.mean(running_mad)\n",
    "            \n",
    "            if verbose:\n",
    "                print('{} Loss: {:.4f} MAE: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'train':\n",
    "                loss2plot[0,epoch] = epoch_loss\n",
    "                acc2plot[0,epoch] = epoch_acc\n",
    "            else:\n",
    "                loss2plot[1,epoch] = epoch_loss\n",
    "                acc2plot[1,epoch] = epoch_acc\n",
    "                \n",
    "                        # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())    \n",
    "                \n",
    "            #print('running mad', running_mad)    \n",
    "        if verbose:\n",
    "            print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    for phase in trainVal:\n",
    "        if phase == 'train':\n",
    "            idx=0\n",
    "        else:\n",
    "            idx=1\n",
    "            \n",
    "        fig = plt.figure()\n",
    "        a = fig.add_subplot(2,2,2*idx+1)\n",
    "        plt.plot(loss2plot[idx,:])\n",
    "        plt.title('Loss per epoch for ' + phase)\n",
    "\n",
    "        a = fig.add_subplot(2,2,2*idx+2)\n",
    "        plt.plot(acc2plot[idx,:])\n",
    "        plt.title('MAE per epoch for ' + phase)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    plt.plot(loss2plot[0,:])\n",
    "    plt.plot(loss2plot[1,:])\n",
    "    plt.title('LOSS')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(acc2plot[0,:])\n",
    "    plt.plot(acc2plot[1,:])\n",
    "    plt.title('MAE')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = torchvision.models.resnet34(pretrained=True)\n",
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = torch.nn.Linear(num_ftrs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([256,256]),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "validation_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([256,256]),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "class HXrayDataset_TL(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.data_frame.iloc[idx, 0])\n",
    "        \n",
    "        #some cases io.imread brings more channels than 1 due to bitsize issues\n",
    "        image = io.imread(img_name)\n",
    "        if len(image.shape) > 2 and image.shape[2] == 4:\n",
    "            image = image[:,:,0]\n",
    "            \n",
    "        # replicate the image into 3 RGB channels\n",
    "        image=np.repeat(image[None,...],3,axis=0)\n",
    "            \n",
    "        image_age = self.data_frame.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        sample = {'x': image, 'y': image_age}\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "HXray_TrainData = HXrayDataset_TL(csv_file='data/train_boneage.csv',\n",
    "                                    root_dir='/beegfs/ga4493/projects/team_G/boneage-training-dataset_final', transform=train_transform)\n",
    "train_loader = DataLoader(HXray_TrainData, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "HXray_ValidationData = HXrayDataset_TL(csv_file='data/validation_boneage.csv',\n",
    "                                    root_dir='/beegfs/ga4493/projects/team_G/boneage-training-dataset_final', transform=validation_transform)\n",
    "validation_loader = DataLoader(HXray_ValidationData, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "dataset_sizes = {'train': len(HXray_TrainData), 'val': len(HXray_ValidationData)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    model = model_resnet.cuda()\n",
    "     #This will optimize only the final layer since other layers the gradient calculation is removed and only parameters from the fc layer is given to the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n",
      "train Loss: 1840.6314 MAE: 34.9177\n",
      "val Loss: 1924.0617 MAE: 35.3332\n",
      "\n",
      "Epoch 1/39\n",
      "----------\n",
      "train Loss: 1793.1414 MAE: 34.4282\n",
      "val Loss: 1889.0610 MAE: 35.1053\n",
      "\n",
      "Epoch 2/39\n",
      "----------\n",
      "train Loss: 1769.6779 MAE: 34.1380\n",
      "val Loss: 1864.8663 MAE: 34.9628\n",
      "\n",
      "Epoch 3/39\n",
      "----------\n",
      "train Loss: 1746.6530 MAE: 33.9188\n",
      "val Loss: 1849.4015 MAE: 34.7360\n",
      "\n",
      "Epoch 4/39\n",
      "----------\n",
      "train Loss: 1728.3459 MAE: 33.7578\n",
      "val Loss: 1847.6862 MAE: 34.4602\n",
      "\n",
      "Epoch 5/39\n",
      "----------\n",
      "train Loss: 1717.4634 MAE: 33.6363\n",
      "val Loss: 1827.0202 MAE: 34.6014\n",
      "\n",
      "Epoch 6/39\n",
      "----------\n",
      "train Loss: 1719.5080 MAE: 33.6642\n",
      "val Loss: 1833.7674 MAE: 34.2079\n",
      "\n",
      "Epoch 7/39\n",
      "----------\n",
      "train Loss: 1705.1560 MAE: 33.5702\n",
      "val Loss: 1819.9638 MAE: 34.2418\n",
      "\n",
      "Epoch 8/39\n",
      "----------\n",
      "train Loss: 1695.6607 MAE: 33.4089\n",
      "val Loss: 1814.9084 MAE: 34.1509\n",
      "\n",
      "Epoch 9/39\n",
      "----------\n",
      "train Loss: 1689.3795 MAE: 33.3707\n",
      "val Loss: 1806.6882 MAE: 34.2189\n",
      "\n",
      "Epoch 10/39\n",
      "----------\n",
      "train Loss: 1675.2778 MAE: 33.2583\n",
      "val Loss: 1807.3195 MAE: 34.1216\n",
      "\n",
      "Epoch 11/39\n",
      "----------\n",
      "train Loss: 1679.6421 MAE: 33.2547\n",
      "val Loss: 1816.1221 MAE: 33.8935\n",
      "\n",
      "Epoch 12/39\n",
      "----------\n",
      "train Loss: 1680.2209 MAE: 33.1786\n",
      "val Loss: 1797.9925 MAE: 34.1873\n",
      "\n",
      "Epoch 13/39\n",
      "----------\n",
      "train Loss: 1683.8576 MAE: 33.2902\n",
      "val Loss: 1799.1222 MAE: 34.0341\n",
      "\n",
      "Epoch 14/39\n",
      "----------\n",
      "train Loss: 1673.2791 MAE: 33.2095\n",
      "val Loss: 1801.2038 MAE: 33.9133\n",
      "\n",
      "Epoch 15/39\n",
      "----------\n",
      "train Loss: 1667.7467 MAE: 33.0406\n",
      "val Loss: 1794.4954 MAE: 34.0451\n",
      "\n",
      "Epoch 16/39\n",
      "----------\n",
      "train Loss: 1659.2468 MAE: 33.0347\n",
      "val Loss: 1800.3157 MAE: 33.8251\n",
      "\n",
      "Epoch 17/39\n",
      "----------\n",
      "train Loss: 1663.5997 MAE: 33.0343\n",
      "val Loss: 1793.9321 MAE: 33.8977\n",
      "\n",
      "Epoch 18/39\n",
      "----------\n",
      "train Loss: 1665.5218 MAE: 33.0589\n",
      "val Loss: 1790.0783 MAE: 33.9667\n",
      "\n",
      "Epoch 19/39\n",
      "----------\n",
      "train Loss: 1674.3926 MAE: 33.2487\n",
      "val Loss: 1792.8490 MAE: 33.8236\n",
      "\n",
      "Epoch 20/39\n",
      "----------\n",
      "train Loss: 1661.8128 MAE: 33.0906\n",
      "val Loss: 1802.7089 MAE: 33.6884\n",
      "\n",
      "Epoch 21/39\n",
      "----------\n",
      "train Loss: 1658.4113 MAE: 33.0312\n",
      "val Loss: 1786.1988 MAE: 33.9519\n",
      "\n",
      "Epoch 22/39\n",
      "----------\n",
      "train Loss: 1644.5638 MAE: 32.8837\n",
      "val Loss: 1786.9991 MAE: 33.8747\n",
      "\n",
      "Epoch 23/39\n",
      "----------\n",
      "train Loss: 1655.7352 MAE: 32.9060\n",
      "val Loss: 1784.5074 MAE: 33.9670\n",
      "\n",
      "Epoch 24/39\n",
      "----------\n",
      "train Loss: 1654.1944 MAE: 33.0698\n",
      "val Loss: 1786.2660 MAE: 33.8562\n",
      "\n",
      "Epoch 25/39\n",
      "----------\n",
      "train Loss: 1657.3418 MAE: 33.0325\n",
      "val Loss: 1785.8573 MAE: 33.8665\n",
      "\n",
      "Epoch 26/39\n",
      "----------\n",
      "train Loss: 1647.9117 MAE: 32.8900\n",
      "val Loss: 1782.4324 MAE: 34.0105\n",
      "\n",
      "Epoch 27/39\n",
      "----------\n",
      "train Loss: 1642.1587 MAE: 32.8440\n",
      "val Loss: 1787.7729 MAE: 33.7094\n",
      "\n",
      "Epoch 28/39\n",
      "----------\n",
      "train Loss: 1647.8217 MAE: 32.9059\n",
      "val Loss: 1780.7329 MAE: 33.9755\n",
      "\n",
      "Epoch 29/39\n",
      "----------\n",
      "train Loss: 1647.5810 MAE: 32.8438\n",
      "val Loss: 1780.0738 MAE: 34.0858\n",
      "\n",
      "Epoch 30/39\n",
      "----------\n",
      "train Loss: 1645.0766 MAE: 32.9230\n",
      "val Loss: 1783.8562 MAE: 33.6702\n",
      "\n",
      "Epoch 31/39\n",
      "----------\n",
      "train Loss: 1639.2735 MAE: 32.7347\n",
      "val Loss: 1777.9449 MAE: 33.8850\n",
      "\n",
      "Epoch 32/39\n",
      "----------\n",
      "train Loss: 1638.0741 MAE: 32.8477\n",
      "val Loss: 1776.8033 MAE: 33.7541\n",
      "\n",
      "Epoch 33/39\n",
      "----------\n",
      "train Loss: 1634.9654 MAE: 32.7069\n",
      "val Loss: 1776.6598 MAE: 33.8150\n",
      "\n",
      "Epoch 34/39\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_resnet_ft = train_model(model_resnet, criterion, optimizer,\n",
    "                       num_epochs=40, trainVal=['train','val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
